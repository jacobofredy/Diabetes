{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes against all ML\n",
    "\n",
    "In this project, we will test all what we studied about classifications using the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head(5); df.tail(5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.columns\n",
    "df.isna().sum()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "First we start with PCA. Using PCA, show the importance of each of the PCA dimensions on a bar plot. What is a reasonable number of dimensions in your opinion to obtain at least 95% explained_var_ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26179749, 0.21640127, 0.12870373, 0.10944113, 0.09529305,\n",
       "       0.08532855, 0.05247702])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of our principal components 0.9494422440130162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "      <th>PCA6</th>\n",
       "      <th>PCA7</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.068503</td>\n",
       "      <td>1.234895</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.496990</td>\n",
       "      <td>-0.109985</td>\n",
       "      <td>0.357183</td>\n",
       "      <td>0.858821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.121683</td>\n",
       "      <td>-0.733852</td>\n",
       "      <td>-0.712938</td>\n",
       "      <td>0.285056</td>\n",
       "      <td>-0.389507</td>\n",
       "      <td>-0.406329</td>\n",
       "      <td>0.757034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.396477</td>\n",
       "      <td>1.595876</td>\n",
       "      <td>1.760678</td>\n",
       "      <td>-0.070395</td>\n",
       "      <td>0.906474</td>\n",
       "      <td>-0.040018</td>\n",
       "      <td>-1.152990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.115781</td>\n",
       "      <td>-1.271241</td>\n",
       "      <td>-0.663729</td>\n",
       "      <td>-0.579123</td>\n",
       "      <td>-0.356060</td>\n",
       "      <td>-0.412520</td>\n",
       "      <td>-0.029247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.359334</td>\n",
       "      <td>-2.184819</td>\n",
       "      <td>2.963107</td>\n",
       "      <td>4.033099</td>\n",
       "      <td>0.592684</td>\n",
       "      <td>1.078341</td>\n",
       "      <td>0.549358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PCA1      PCA2      PCA3      PCA4      PCA5      PCA6      PCA7  \\\n",
       "0  1.068503  1.234895  0.095930  0.496990 -0.109985  0.357183  0.858821   \n",
       "1 -1.121683 -0.733852 -0.712938  0.285056 -0.389507 -0.406329  0.757034   \n",
       "2 -0.396477  1.595876  1.760678 -0.070395  0.906474 -0.040018 -1.152990   \n",
       "3 -1.115781 -1.271241 -0.663729 -0.579123 -0.356060 -0.412520 -0.029247   \n",
       "4  2.359334 -2.184819  2.963107  4.033099  0.592684  1.078341  0.549358   \n",
       "\n",
       "   Outcome  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x_pca', ylabel='var'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "features = df.iloc[:,0:8].values # independent variables\n",
    "y = df.iloc[:,8:9].values # dependent variable\n",
    "\n",
    "#Standardizing my data\n",
    "x = StandardScaler().fit_transform(features)\n",
    "\n",
    "#pca = PCA(.95) #instead of reducing it by number of components, I can elect to keep 95% of variance\n",
    "pca = PCA(n_components = 7) # however if I select the above we get 99% variance\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "\n",
    "pca.explained_variance_ratio_ #variance of the two components that resulted in at least 95% of variance kept\n",
    "print(\"Sum of our principal components\",pca.explained_variance_ratio_ .sum())\n",
    "\n",
    "# Concat outcome with new reduced PCA components\n",
    "target = df.iloc[:,8:9]\n",
    "pca_df = pd.DataFrame(data=x_pca, columns =[\"PCA1\", \"PCA2\",\"PCA3\",\"PCA4\",\"PCA5\",\"PCA6\",\"PCA7\"])\n",
    "new_df = pd.concat([pca_df, target], axis = 1)\n",
    "new_df.head(5)\n",
    "\n",
    "# Plotting the PCA components\n",
    "df1 = pd.DataFrame({\"var\": pca.explained_variance_ratio_, \"x_pca\":[\"PCA1\", \"PCA2\",\"PCA3\",\"PCA4\",\"PCA5\",\"PCA6\",\"PCA7\"]})\n",
    "sns.barplot(x= \"x_pca\", y = \"var\", data= df1)\n",
    "plt.show()\n",
    "\n",
    "# 7 is the right number of components to reduce our data to as I summed the variance for each principal component\n",
    "# and we get a total of around 95%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "Do clustering using KMeans on the original dataset (not the PCA) using K=2. Calculate Homogonity and Completeness score. Is that a good clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-5.149462054959605e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n  No, it is not good clustering as the scores for both homogeneity and completeness are really low, \\nwhich means that our data was not clustered correctly as it contains data that should not go into\\nthat specific cluster.If we had effective/efficient clustering then our homogeneity and completeness score would be close to 1. \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "from sklearn import metrics\n",
    "\n",
    "df.head(5); df.tail(5)\n",
    "x1 = df.drop(\"Outcome\", axis = 1) #features \n",
    "y = df[\"Outcome\"] #target\n",
    "\n",
    "kmeans_model = KMeans(n_clusters = 2).fit(x1)\n",
    "\n",
    "y_pred = kmeans_model.predict(x)\n",
    "\n",
    "metrics.homogeneity_score(labels_true = y, labels_pred = y_pred)\n",
    "#metrics.completeness_score(labels_pred = y_pred, labels_true = y)\n",
    "metrics.completeness_score(labels_pred = y_pred, labels_true = y)\n",
    "'''\n",
    "  No, it is not good clustering as the scores for both homogeneity and completeness are really low, \n",
    "which means that our data was not clustered correctly as it contains data that should not go into\n",
    "that specific cluster.If we had effective/efficient clustering then our homogeneity and completeness score would be close to 1. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "Split the original dataset (not the PCA) to have 30% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, random_state = 66, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Using LR, what is the accuracy, precision and recall and F1 score for the training and the test data? Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.7635009310986964\n",
      "Test accuracy 0.7835497835497836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       160\n",
      "           1       0.68      0.56      0.62        71\n",
      "\n",
      "    accuracy                           0.78       231\n",
      "   macro avg       0.75      0.72      0.73       231\n",
      "weighted avg       0.78      0.78      0.78       231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       340\n",
      "           1       0.72      0.58      0.64       197\n",
      "\n",
      "    accuracy                           0.76       537\n",
      "   macro avg       0.75      0.73      0.73       537\n",
      "weighted avg       0.76      0.76      0.76       537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjacobo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbeb86e5450>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "model=logreg.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "print(\"Training accuracy is\", train_score)\n",
    "\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(\"Test accuracy\", test_score)\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_train = model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(classification_report(y_train, pred_train))\n",
    "\n",
    "# PLOT THE ROC CURVE\n",
    "prob_test = logreg.predict_proba(X_test)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, prob_test[:,1])\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the test precision curve and accuracy curve for decision thresholds between 0.1 to 1 with a step of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbea8364bd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbea8372210>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvh0lEQVR4nO3dd3iUVfbA8e9JSOgQIKEnhK5IJyIoIgpipYgNxYYFdGV3ravurgXcoruW5bdiQUEsICC6CjYEAVERJUiRYiBACKEmgUAaIcnc3x83gRBSBjKTd8r5PE8eZ+a9eefwmpzcue+594oxBqWUUv4vxOkAlFJKeYYmdKWUChCa0JVSKkBoQldKqQChCV0ppQJEDafeODIy0sTGxjr19kop5ZdWr16dZoyJKuuYYwk9NjaW+Ph4p95eKaX8kojsLO+YDrkopVSA0ISulFIBQhO6UkoFCE3oSikVIDShK6VUgKg0oYvIdBE5ICIbyjkuIvJ/IpIoIutFpLfnw1RKKVUZd3roM4DLKzh+BdCx6Gsc8FrVw1JKKXW6Kq1DN8YsF5HYCpqMAN41dh3elSISISItjDF7PRWkUko5KTk9h49+ScFTy40PPrsZPaIjPHKukjwxsagVsKvE85Si105J6CIyDtuLJyYmxgNvrZRS3jdjRRLTf9iBiGfO17RBLZ9N6G4zxkwFpgLExcXpzhpKKb+QmpVH28i6LH1kkNOhVMgTVS67gegSz1sXvaaUUgEhPSuPJnXDnQ6jUp5I6POB24qqXfoBh3X8XCkVSNKzjtGknu8n9EqHXETkA2AQECkiKcDTQBiAMeZ14AvgSiARyAHGeitYpZRyQnp2Hn1iGzkdRqXcqXK5qZLjBrjfYxEppZQPKXQZDmYfIzJIhlyUUipgZeQcw2WgSb2aTodSKU3oSilVgfTsYwB+MYauCV0ppSqQlpUHQJO62kNXSim/lp5le+iR2kNXSin/ll7cQ9cxdKWU8m/p2ccIEYioHeZ0KJXShK6UUhVIy8qjcd2ahIR4aCEXL9KErpRSFUjLOuYX4+egCV0ppSqUnpVHpB+Mn4MmdKWUqlB6tn+s4wKa0JVSqkLpWcf8ogYdNKErpVS5juYXkpVXoD10pZTyd8XT/vWmqFJK+bl0P5r2D5rQlVKqXMXT/nXIRSml/FzxwlxatqiUUn7On5bOBU3oSilVrvSsPGqHhVInvNLN3XyCJnSllCqHv2wOXUwTulJKlSM1K88vls0t5lZCF5HLRSRBRBJF5PEyjrcRkW9EZL2ILBOR1p4PVSmlqld61jGiAqmHLiKhwBTgCqALcJOIdCnV7AXgXWNMd2AS8E9PB6qUUtUtPTvPb2rQwb0eel8g0Riz3RhzDJgNjCjVpguwpOjx0jKOK6WUXzHGBOQYeitgV4nnKUWvlbQOGFX0+Bqgvog0KX0iERknIvEiEp+amnom8Sql1EmMMXy0OoWMnGMePe+R3AIKXCbwxtDd8AhwkYisAS4CdgOFpRsZY6YaY+KMMXFRUVEeemulVDD7bV8mD3+4jrEzVnE0/5S0c8bSsosnFQVWD303EF3ieeui144zxuwxxowyxvQC/lL0WoanglRKqfIkHsgCYE1yBg/OWYvLZTxy3uPT/gNsDH0V0FFE2opIODAamF+ygYhEikjxuZ4Apns2TKWUKtu21CxE4NHLOvPlhn3844vNHjnv8YW5/KiHXun0J2NMgYhMABYCocB0Y8xGEZkExBtj5gODgH+KiAGWA/d7MWallDpuW2o20Y3q8LtB7UnNzOOt73cw6+dkKtvS+fwOkfx9ZFeaNqhV5vE0P5v2D24kdABjzBfAF6Vee6rE43nAPM+GppRSldt2IIv2UXUREZ68ugvRjeuwNyO3wu85WlDIh/EpXPrycp4d2ZXhPVqe0qa4h964ToAldKWU8kUul2F7Whbnt7dFdaEhwl0D2rr1vWMvaMvDc9fxhw/W8K+vfiMs9OQR6PSsPCLqhFEj1H8m1GtCV0r5rd0ZuRzNd9G+ab3T/t72UfWYd29/ZqxIYn3K4TLbxMU2qmqI1UoTulLKb21LtRUu7aNOP6ED1AgN4e4L23kyJEf5z2cJpZQqZVtqNgAdzqCHHog0oSul/Na21Cwa1QmjcV3/uXHpTZrQlVJ+y1a4aO+8mCZ0pZTPcrkMSWnZ5R7flpqtCb0ETehKKZ+1YP0eBr2wjBWJaaccO5yTT1pWHu2b1nUgMt+kCV0p5bNWJR0EYOKCTRQUuk46lljFCpdApAldKeWz1qccpmHtMBL2ZzLzp+STjhWXLGqFywma0JVSPimvoJDNe48wum80F3RowkuLtnAo+8Sa59tSswgPDaF1ozoORulbNKErpXzS5r2Z5BcaeraO4Olh55CVV8CLixKOH992IJu2kXUJDalsGa7goQldKeWT1qdkANA9OoJOzepza782zPopmRk/7LBruKRm6Q3RUnTqv1LKJ63bdZjIeuG0bGiXt314aCeS0rN5ZsEmvtywj50Hc7iqewuHo/Qt2kNXSvmk9SkZdG8dgYgdUqlfK4y37ziXf13bnY17jlDoMlrhUor20JVSPicrr4DE1Cyu7n7yOuUiwg3nRnNBx0g+Wp3C0HOaORShb9KErpTyOb+mHMYY6B7dsMzjrSJq84fBHas5Kt+nQy5KKZ9TfEO0R+sIR+PwN9pDV8ofZWVBUlLZx1q1gkb+tTFDaetTDtO6UW1dRfE0uZXQReRyYDJ2k+i3jDHPlToeA7wDRBS1ebxoH1KllKetWAHXXgv79pV9vEEDmDULrrqqeuM6TZlH89l/5CgdmtY/5di6lAztnZ+BShO6iIQCU4BLgRRglYjMN8ZsKtHsr8BcY8xrItIFu6F0rBfiVSq4TZ0KEyZATAzMnAnhpXqwLhc89xwMGwaTJsGf/wwh1TOyet1rKzhaUMiDQzpxyVlNj1enlMUYw+9m/sJ3W9MY1bsVT1xxNlH1awJ2L8+UQ7nc1r9NtcQdSNzpofcFEo0x2wFEZDYwAiiZ0A3QoOhxQ2CPJ4NUym8lJ8NTT8Fll8GoUVCzJuTnw4IFMGcOZJe/NOwpjhyB776z5/rgg/KHVa6+GsaNgyeftL35xx6DgQOhggRbVdtTs4jfeYg64aHc9U48PaMjeHpYF3rFlB3jok37+W5rGgM6RLJg3R4WbdzPbee3oUGtMJIP5gDQXXvop82dhN4K2FXieQpwXqk2zwBfi8jvgbrAkLJOJCLjgHEAMTExpxurUv7FGBg/Hr76Ct55ByIj4YorYNEiO1zSogW0bFn5eUp6+mmbqENDy29Tpw689x7ExcEzz8CgQXDWWXD99fZYWe1HjYLWrU+8tmuXjXvAADj77ErDWvLbAQC++MOFrNyezuRvtnLrtJ+ZM74f57Q8uVIlr6CQv32+mY5N6/H22HNJPpjDxAWbmLJ02/E2jeuG061V2RUuqgLGmAq/gOuw4+bFz28FXinV5iHg4aLH/bG995CKztunTx+jVECbM8cYMOall4xZuNCYa681pk4dY66+2pj5843Jz/d+DNnZxrz9tjH9+tlYyvsKCTFm2DBjpk618YWEnDg2cKAx779vTG5uuW8z+o0fzdCXvj3+fG9Grun/j8Um7m+LTHJ69kltpyzdato89plZvuXASa/n5BWY7Lx8k52Xb44VFHr0MgQSIN6Uk1fFHi+fiPQHnjHGXFb0/ImiPwT/LNFmI3C5MWZX0fPtQD9jzIHyzhsXF2fi4+PP5G+QUr7v8GHbK27ZEn7+ueIedXXJy7MpurTdu2H6dJg2Dfbvh+bN4c474brr7KeJqVNh2zZo0gRuvx3uucf+24oczs2nz7OLuGdgOx67/MTrW/Znct1rK4isX5OP7j2fRnXD2X/kKBe/sIwLOkTy5m1x1fGvDjgistoYU+bFcyeh1wC2AIOB3cAq4GZjzMYSbb4E5hhjZojI2cA3QCtTwck1oauANmECvPYa/PSTHfrwB/n5sGEDdO2KqVGDb7ek0jM6gohaNWDJEpvY//c/KCiAiy6yw0mjRvHN0nVsnPQS43f+QM1mUXb8/uaboUEDft5xkFum/cSxghObU4SHhrDooYG0aaILa52JKiX0ohNcCfwHW5I43RjzdxGZhO36zy+qbHkTqIe9QfonY8zXFZ1TE7o6LQsWwEsv2aRTWt268I9/QJ8+3o1h82ab1Pbtg9tug6FDbc971y7bu12yxFaZGAM//gi//z1MnuzdmLzkw/hdPDpvPXXDQ7m1fyx3X9iWyHo1bQ/+7bftddixAxo2xHXkCAAy9DJk315Yt87+P3noIXj6aeJ3Hea7rSe2kDuvbWPO7xDp1D/N71U5oXuDJnTlFpfLlt9NnAgdO9pyvdI2bYKDB22Sue02+1piIsydC5mZVY/BGFst8t13EBZm67zT06FNGzv0sGiRbXPeeTaRgZ3c89//2rYOOVbgosDlok746c0fPHI0n0teWEariNq0aVKXz9bvIbxGCLec14Z7B7W3id3lgsWLcb0/k2nJBey9bgxPTbjSXoeff4aXX7ZVPJVV5KjTpgld+YbkZPj11xPP27aFLl1ObrN3L/zyy4nnb74Jn34Kd9xhhzBq1Tr1vKmpcOONsHQpjB1re8yLF9tjpeu0z1SbNnD33TaOiAgb0xtv2LHlm2+2x9q29cx7uWH1zoOs3H6wzGOpmXms3ZXBpr2253x9n9aMG9jO7SGOZz/bxPQfdrBgwgC6tmrI9tQsXlmayCdrdlOzRii3nx/L+IHtaFQ3nNU7D3Htayv47029GNajVMXOm2/C/ffbP8LPPQe1a5/6Zs2bQ+/e5ZdUZmZCQoL/DFtVA03oynnGQNeutjddUv/+diy2eXPbw54/347RFgsNhf/8xyaGiuqoCwrg0Udt25gYm2DvvNP2lANMoctwwXNL2HfkaJnHa4eF0q11Q3pGR3AkN5+Pf9lNgcvFBR0iqVtGb71OeCij+8bQt21jtuzP5IrJ33HjudH845puJ7XbnprF5G+2Mn/dHurVrMG9F7UnPesY7/yYxC9PXkrD2mGnBlPZrFaAbt3sz8B11534g52YaH8eZs2yyxy8/rptozShKx+werXtZU2caGuxjbFDGFOnwpYttk1kpO0Bjxx5omfdrFnZwyzl2bcPoqJ8o6rES1ZsS+PmN3/iPzf25IpuzU85HhYSQkiJbdn2HznKtO93sHxLaplFLvszj5KRk0+/do05mu9iR1o2Sx8ZVO46Kgn7Mvn3wgQWb94PQL92jZk9rn/5AR85YnvZZVmzxn7SKfmprFjt2vaTV0oKLFsGX38NF19c/vsECU3oynkPPQRTptiEW3I81RhYvtyOgV95pZ1JqSr0+EfrWbBuD/F/vZTa4VX/w5V7rJBZPyfzxrfbOJCZx6QR53Bb/9hKvy8+6SBvLN/ODXHRXNqliuuSx8fD99+fKKuMiIBrrrH/PXzYfpLbv99WDXXoULX38nOa0JWzCgshOtreNPzf/5yOxq/lFRRy7t8WM+TsZrx0Y0+PnvtofiHrdmXQt23jCtdhccS2bdC3LzRtasfmL7jAq0sZ+LKKEroun6u8b+lSe7NzzBinI/F7S39L5cjRAkb08vy9gVphoZzXronHz+sR7dvDxx/DiBFw4YX2ZvrYsXb5BLBDdFdeeaLKKEhpQlfeN3OmLd+7+mqnI/F7n67dTWS9cC5o76OJ15suusjOap0zx467P/royce7d7efANu1cyY+H6A7Finvys2Fjz6ylQ5llRwqtx05ms83vx3g6u4tqREapL+6deva6qWffrLlqVu22K+PP7Zlseeee6JkNQhpD11512ef2VpiHW6psq827ONYgYsRPU9zhcZAVXJ1yI4dbfnjyJF2MpM7q1h2726XKbjqKqhRTip0ueyQ4dSpsHOnnXNw660+O1FKb4oq70lIsOOcSUm2NxXApYSekpqZx5OfbGB3Ru4px3Zn5FK/Vg2WPTLI925a+orMTDuJqaK6d7A36hctgj17bPK/8MJTb7IaY8ttExOhcWNbPrt2rf2kecMNcO+90K9ftd+c1Zuiqnp99ZX9pfr2W9vzmTxZk7kbtu7PZOyMVaRl5dG/XZNTknZU/Zpc36e1JvOK1K8Pf/+7e20LCuwnyDfftPXwZYmOtmvQF096Kq6bnzkT3n3XfiooWogMsLXzw4bZORUO0B668qydO22dcOvWdmbf2LF2cpA6RWpmHodz7WJj21KzeOTDddQKC2Xa7XG6W4+vy8y0a9SUNSkqPNzeMxo/3is7RWkduqo+48fDjBm2brjkGKc6ydKEA9zzTjwFrhO/f52b1Wf62HNpFVHGmifKd6Wn2yEcsEM406bZHaOK18QfN86uI9+4sUfeThO6qh7FvfNx4+ysUFWmpLRshr/yPa0a1eG+Qe0BqBEiDOwURb2aOgoaEHJy7Gqfb7wBK1faGdDXX29/NwYMqFKvvaKEHqS1T8or/vlPu8P84487HYnPSMvK49EP17Fo035cLkPOsQLufX81ISHC1Fv7MLxHS4b3aMmV3VpoMg8kderYdYl+/NGuD3/33XbhuYED7SJ1n3/ulbfVnyDlGcnJdhuzu++2N5IUAF9u2MeHq1P4cHUKHZvWI6p+TRL2Z/LO2L5ENy5jw2YVeLp3h1degeefPzEpyktFAtpDV57xz6ItZp94wtk4fMya5ENE1gvnPzf2JESEFdvSeWRoZwZ2inI6NFXdSk6Kuuwyr7yF9tBV1RgDL75oJ16MH6+981LWJmfQK6YRI3u1YkTPluxIy6ZtZHCvN6LwWu269tDVmcvJsTNAH30URo2Cf//b6Yh8yqHsY2xPy6ZXTAQAIkK7qHpaR668RhO6OjNJSXYJ09mz7QbNc+cG/Up3pa1NyQCgV7RvThNXgcethC4il4tIgogkisgpJQwi8rKIrC362iIiGR6PVPmOJUvs7kM7dtiZdk88EbRrU1dkTXIGIQLdWzd0OhQVJCodQxeRUGAKcCmQAqwSkfnGmOObQxpjHizR/vdALy/EqpxmjJ3G/8gj0LkzfPKJXRRJlWlN8iE6N29AXS1HVNXEnR56XyDRGLPdGHMMmA2MqKD9TcAHnghO+ZDcXLjtNnjwQRg+3E6W0GReLpfLsHZXxvHxc6WqgzsJvRWwq8TzlKLXTiEibYC2wJJyjo8TkXgRiU9NTT3dWJVTkpPt7Lb334dJk2DePLsIkirX9rQsMo8W0Cs6wulQVBDx9GfB0cA8Y0xhWQeNMVOBqWCn/nv4vZWn7dljJwtNngx5eXam27BhTkflF35JzgCgV4zeEFXVx50e+m6gZHFx66LXyjIaHW7xfzt22NXiYmLgySehRw/4+WdN5qdhTXIGDWrVoJ3WnKtq5E5CXwV0FJG2IhKOTdrzSzcSkbOARsCPng1ReU1GBixbZnvfxb75xlawLF4MDz1kt/davNiuGqfctib5ED1jGhESotU/qvpUOuRijCkQkQnAQiAUmG6M2Sgik4B4Y0xxch8NzDZOLd+oTs/69Xa7rh077GL8d9wBERHw1FNw9tm2gqVDB2dj9FNZeQVs2Z/JZec0dzoUFWTcGkM3xnwBfFHqtadKPX/Gc2Epr5o3z67P3LAhvPUWfPEFvPyyXdN51Ci7nrne9DwtG3Yf5u0fkihwuTicm4/LoBUuqtppgWywmTwZHngAzj/fJvYWLeCuu2DvXrsH6MCBdglc5bbNe48w5q2fcBlDk7rhgE3mcbGe2dBAKXdpQg8mn31m68hHjYJZs+yi+8VatLBfqlyFLsNfP/mVFdvSGT+wPdf1ac2uQzncOu0n6oSHMnd8f10SVzlKdywKVJs22fHxoUMhLAw2bID+/aFTJ/juO7sAv3Jbocvw2Efrmbc6hdgmdUhKz6F1o9rkF7oodBnmjO9P+6h6ToepgkBFOxZpDz0Q7dgBF10EaWm21z12rN3Qtn59+PRTTeanyeUyPF6UzB8Y0pE/Du7IsoRUXl68hZRDucy8+zxN5sonaEIPNJmZdmp+QYGdFDRvnt18Ijwcli/XjZuLFLoMX27Yy/Tvd7An42iFbQtcLtKyjvHHwR15YEgnAC4+qymDOkdR4DKEheo9B+UbNKEHksJCuPlm2LwZvvoKhgyxvfPkZMjOtuWIQS73WCEfr0nhzeXbSUrPoV1kXQZ2ikSouF68Z0wEo889efMOESEsVOvMle/QhB4ofv3Vrkv+2Wd2/8IhQ04ci4lxLi4fse/wUd5bmcSsn5I5lJNP99YNeW1Mb4ae05xQnfyjAoQmdH+Wk2M3lnjjDbv6Yc2a8Je/wO9+53RkPsEYw8rtB3l/5U4WbtxHoTEM7dKMOy9oS9+2jXXnIBVwNKH7o4QEmDIF3nvPTt/v3Bleeskub9ukidPR+YQDR45y+9ur2Lz3CA1rhzH2glhu6deGNk10bRUVuDSh+5sZM+Dee+1mE9deazdmHjhQdwwqIa+gkPHvryYpLZt/Xded4T1aUiss1OmwlPI6Tej+Ij8fHn4Y/vtfGDwYZs6EZs2cjqpaGWM3jfh8/V5W7kinoNDOoagVFsod58cyomdLAP76vw2sSc7gtTG9uaKbTpZSwUMTuj84cABuuAG+/dYm9eeegxrB9b9u9c6D/HH2WlIO5RIWKvRt25i64fYa7EzP4YE5a3nnxyTOjW3Mh6tT+MMlHTSZq6ATXFnBH61eDddcA6mpdsegMWOcjqjaZecV8MfZawF44foeXNqlGQ1rhx0/7nIZ5v2Swr++SmBN8naGnN3seL24UsFEE7qvKiyEd9+1FStNm8IPP0Dv3k5H5Yh/frmZ3Rm5fDi+f5kLXoWECDfERXNltxZ8vXEfl53TXNchV0FJE7qvKd727c037YSgQYNsaWJUlNOROeKHxDTeX5nMXQPaVrp6Yb2aNRjVW2fCquClCd0XuFzw9de2nnzBAts7HzIEXnjBDrcE0Xh5QaGLrQeyMMZOz//TvPW0i6zLI0M7Ox2aUj4veDKFL9q370RvPCnJ9sIffhjuuScodwvKPJrPnTNWsSrp0PHXRGDevf2pHa5lh0pVRhO6Ew4fhnHj4OOP7SJal1xiK1dGjjx5jfIgcjg3n9un/8yG3Yd58uoutIqoDUCbJnU4u0UDh6NTyj9oQnfCK6/YcfGHH7aJvVNwVGS8uXw7X2/ad/x5w9rhdGlRn87NG/Dat4kk7Mvk1aL1VZRSp8+thC4ilwOTsZtEv2WMea6MNjcAzwAGWGeMudmDcQaOggI7Vl48Rh4kjDG8uiyROuE1aNOkDsZAUno2S37bj8tAeI0Qpt4ax8VnNXU6VKX8VqUJXURCgSnApUAKsEpE5htjNpVo0xF4ArjAGHNIRPS3sjyffw67dtm9PYPIttRsDuXk89jlZzG674nVH4/mF5KwL5NGdcKJaaIbbyhVFe700PsCicaY7QAiMhsYAWwq0eYeYIox5hCAMeaApwMNGK++ajeZGDbM6Uiq1eqdBwGIi2100uu1wkLpER3hQERKBR53tlppBewq8Tyl6LWSOgGdROQHEVlZNERzChEZJyLxIhKfmpp6ZhH7sy1bbHni+PFBVYoIEJ90iEZ1wnSrNqW8yFN7Z9UAOgKDgJuAN0UkonQjY8xUY0ycMSYuKhgnyrz+uk3kd9/tdCTVbvXOQ/Rp00jXIFfKi9xJ6LuBkntvtS56raQUYL4xJt8YswPYgk3wqlhODrz9tl3ytnlwVXGkZ+WxPS2bPm0qnumplKoadxL6KqCjiLQVkXBgNDC/VJtPsL1zRCQSOwSz3XNh+rnMTLjlFrsZxf33Ox1NtYvfaScKlR4/V0p5VqUDucaYAhGZACzEli1ON8ZsFJFJQLwxZn7RsaEisgkoBB41xqR7M3C/sXWrnTCUkAAvvwwXXuh0RNVu9c5DhIeG0K1VQ6dDUSqguXVnzhjzBfBFqdeeKvHYAA8Vfaliq1fbzShq1ICFC+3jIBSfdJBurRvqrkFKeZmnboqqsjz6KNSqBatWBW0yP5pfyIbdR4hro8MtSnlbcNXOVafly2HpUjvM0rat09E45tfdhzlW6KKPJnSlvE576N4ycaKtZhk/3ulIHLUqyU4o0oSulPdpD90bvvsOliyBl16C2rWdjsYxLpdhRWI67aLq0qRecK4iqVR10h66N0ycCM2aBXXv/Mdt6Qx75Xu+T0zjMl09UalqoT10T/vhB/jmG3jxRagTnItN/WneOubGp9AqojaTR/dkeI+WToekVFDQhO5pM2ZAgwZw771OR+KIhH2ZzI1P4ZZ+Mfz1qi5aqqhUNdIhF08y5kS9eZD2zj+M30VYqPDQpZ01mStVzTShe1JCgl3r/LLLnI7EEfmFLj5Zu5vBZzWjcd1wp8NRKuhoQvekhQvtf4M0oS9LSCUt6xjX9WntdChKBSVN6J60cKHdHzQ21ulIHPFh/C4i69VkUOcgXBpZKR+gCd1Tjh6FZctg6FCnI3FEelYeS347wKjeragRqj9WSjlBf/M85fvvITc3aIdbPlm7hwKX0eEWpRykCd1TFi6EsDAYNMjpSKpdfqGLuat20aN1Qzo1q+90OEoFLU3onrJwIQwYAPWCa8/MYwUufj9rDQn7M7lzQPAuQqaUL9CE7gl79sCvvwbdcMuxAhf3z/qFrzbu46mruzCiZ+m9w5VS1UlninrCokX2v0F0Q/RofiH3z/yFb347wKQR53Bb/1inQ1Iq6GlC94S334bWraFHD6cjqRbZeQWMey+eHxLT+dvIrtzSr43TISml0IRedcuWwbffwuTJEBL4I1iHc/O5c8Yq1iQf4sXre3CtVrUo5TM0oVfVxInQogXcc4/TkXhdamYet0//ma0HMnl1TG8u79rC6ZCUUiW41aUUkctFJEFEEkXk8TKO3yEiqSKytujrbs+H6oOWL7c99MceC/iNLJLTc7ju9RXsSMvmrdvP1WSulA+qtIcuIqHAFOBSIAVYJSLzjTGbSjWdY4yZ4IUYfVfxNnPjxjkdiVdt3HOY26evosDlYuY959E7RreTU8oXuTPk0hdINMZsBxCR2cAIoHRCDy7F28y9/HLA9s5TM/N4b+VOpn+/gwa1ajB7XH86NNWJQ0r5KncSeitgV4nnKcB5ZbS7VkQGAluAB40xu0o3EJFxwDiAmJiY04/WV7hc8Kc/Bew2c2lZeTz/5W98unYPxwpdDDm7Kc+O7EqLhoH5h0upQOGpm6ILgA+MMXkiMh54B7ikdCNjzFRgKkBcXJzx0HtXv6lTYeVKePddv+6dHytwsf/IUVo3qo2IAJB4IJOxM1ax/0geN54bzdgLYmkXFVyzX5XyV+4k9N1AdInnrYteO84Yk17i6VvAv6oemo/atw8efxwuuQRuucXpaM7YjrRsJsz6hY17jtAjOoK7BrQlonYY98/6hZo1Qpg7vj89oyOcDlMpdRrcSeirgI4i0habyEcDN5dsICItjDF7i54OBzZ7NEpf8uCDdlXF116Dol6tv/l07W7+/PGvhNUI4feXdGDBuj384YM1AHRsWo/pd5xLdOPg3EJPKX9WaUI3xhSIyARgIRAKTDfGbBSRSUC8MWY+8AcRGQ4UAAeBO7wYs3MWLoTZs+GZZ+xGFn7oxa8T+O+SRM6NbcTk0b1oGVGbB4d0YslvB4jfeYj7BrWnYe0wp8NUSp0BMcaZoey4uDgTHx/vyHufEZcLunWD/Hy7EFfNmk5HdNre+zGJJz/dyA1xrfnHNd10Iwql/JCIrDbGxJV1TGeKumvePNi0yfbQfTyZG2P455e/sXnvEW7rH8vgs5qyePN+np6/kcFnNdVkrlSA0h66O1wu6N4djIH16yE01OmIylWczKcu307D2mEczs2nbWRd9mTkclaLBnxwz3nUCde/40r5K+2hV9VHH8HGjfDBBz6dzAFeWZLI1OXbubVfG54a1oWvNuzjre93EBYqTLs9TpO5UgFMe+iVKe6du1x27NxHE/qOtGxm/bSTN7/bwaherXjh+h6EhPhnFY5SqnzaQ6+Kjz+2vfNZs3wqmbtcho17jrB8aypf/LqXjXuOADCqVyv+dV13TeZKBSFN6JV5/nk46yy44QanIwHgUPYx/v11Al/+updDOfkA9IiO4K9Xnc1V3Vvo9Hylgpgm9Ir89hvEx9sFuBzunRtj+Gz9Xp6Zv5HDufkM69GSizpFcUGHSKLq+3bVjVKqemhCr8jMmXYXotGjHQ1jT0YuT326kcWb99OjdUNm3nMeZzVv4GhMSinfowm9PMbYcfPBg+2a5w4odBneWZHEi18n4DLwlyvP5s4BbQnV8XGlVBk0oZdn5UrYvh2eesrrb2WMYUdaNutSMtiw+whpWXlk5OSzMz2bpPQcBnWO4tkRXXV9FaVUhTShl+f996FWLbjmGo+f2hjD0oQDxCcd4tfdh1mfcpjDufYGZ62wEJo1qEVE7TDaNKnLw0M7c3X3FseXt1VKqfJoQi9Lfj7MnQvDh0MDz49Vz1iRxMQFm6gRInRuXp8ruzWnR+sIesZE0LFpfR1SUUqdEU3oZfn6a0hLgzFjPH7qvYdzeWFhAhd1iuKNW/tQK8x3atuVUv5NV2gqy8yZ0LgxXH65x0/9zPyNFBrD30Z21WSulPIoTeilrV9vh1tuuQXCwz166sWb9rNw437+MLij3uBUSnmcJvSSXC676XOjRh6vbknLyuPp+Rvp1Kwe91zYzqPnVkop0DH0k5Xc/LlJkyqfzhjDqqRDvL9yJ19t2EehMcwZ148wXYtcKeUFmtCLeXjzZ2MMf/t8M9O+30H9WjW4+bwYbukXQ4em9T0QrFJKnUoTerGHHrKbP7/6qkc2f3512Tamfb+DW/u14c9Xnk3tcL0BqpTyLrc++4vI5SKSICKJIvJ4Be2uFREjImWu1euzvv7abl7xxBPQuXOVT/fBz8n8e2ECI3u2ZOLwczSZK6WqRaUJXURCgSnAFUAX4CYR6VJGu/rAH4GfPB2kV+Xmwn33QadONqFX0bKEA/zlf78yqHMU/9ZNJpRS1cidHnpfINEYs90YcwyYDYwoo92zwPPAUQ/G531//7tds+X116u8+XOhy46bx0bW5dUxvfXmp1KqWrmTcVoBu0o8Tyl67TgR6Q1EG2M+r+hEIjJOROJFJD41NfW0g/W4TZvgX/+CW2+Fiy+u8uk+W7+HxANZPHRpJ927UylV7archRSREOAl4OHK2hpjphpj4owxcVFRUVV966oxxg611KsHL7xQ5dMVFLqYvHgrZzWvz5VdW3ggQKWUOj3uJPTdQHSJ562LXitWH+gKLBORJKAfMN/nb4yuWAHLl8Ozz0LTplU+3Sdr97A9LZsHhnTScXOllCPcSeirgI4i0lZEwoHRwPzig8aYw8aYSGNMrDEmFlgJDDfGxHslYk959VVo2BDuuKPKp8ovdPF/32zlnJYNuOycZlWPTSmlzkClCd0YUwBMABYCm4G5xpiNIjJJRIZ7O0Cv2L8fPvzQJvO6dat8uvdX7iT5YA4PDumk65YrpRzj1p07Y8wXwBelXitzsRNjzKCqh+Vl06bZNc/vu6/Kp/p07W6e/WwTF3aMZPDZVR+6UUqpMxV8dXWFhbZEcfDgKk8imr9uDw/OWUvfto1549Y+2jtXSjkq+GrrPv8cdu2C//znjE+RV1DI+yuT+fvnm4iLbcz0O87VMkWllOOCLwtNmQItW9rt5U7T0fxC5qzaxWvLtrHvyFEGdoritTG9NZkrpXxCcGWin3+267ZMnAg1Tu+fvvdwLndMX0XC/kz6xjbmxRt6cH77JjrMopTyGcGT0AsK7OYVrVrBAw+c1rdu3Z/J7dN/5sjRAqbdHsclZzXVRK6U8jnBk9D/7/9g7Vr46CNo0MDtb4tPOshd78QTXiOEOeP7cU7Lht6LUSmlqiA4EnpyMjz5JFx9NVxzjdvftmV/JmPfXkVk/Zq8e2df3QdUKeXTAj+hGwMTJtjHr7zi9uYVaVl53DljFbXCQ5l593m0jKjtxSCVUqrqAj+h//QTLFgAzz8Pbdq49S1H8wsZ9248aVl5zBnXX5O5UsovBH5CnzkTatWCe+91q3lSWjaTPtvEL8kZvDqmNz2iI7wbn1JKeUhgJ/T8fJgzB4YNq/RGaOKBLKYsTeTTtbsJCw3hmWFduLKbLoOrlPIfgZ3QFy+G1FQYM6bcJll5BUxevIXpPyQRHhrC3Re24+4L29K0fq1qDFQppaousBP6zJnQqBFccUWZh7/asI9n5m9k35GjjD43mkcu60xkvaptQ6eUUk4J3ISenQ2ffGJ75+HhJx0yxvDSoi38d0kiXVo0YMqY3vRp08iZOJVSykMCN6F/+qlN6qWGW44VuHjso/X8b81uboyL5m/XdNXNnJVSASFwE/rMmRAdDQMGALZX/uO2dF5evIVVSYd4ZGgn7r+4g07hV0oFjMBM6Nu3w8KF8MgjFBiY8d123l+5k6T0HBrWDuM/N/ZkZK9WTkeplFIe5d8JPSMDfvgBLrzwRFnismVw/fVQty55t4/l/vd/YfHm/fSNbcwfh3Tkiq4tqBUW6mTUSinlFf6b0DduhJEjITHR7gt6000QE2OXxu3Ykaw5H3Ln8oOsSjrIpBHncFv/WKcjVkopr/LLhH5s7jxC77yD3Jp1+Pj+v9E/+Vfaz5pFSE4OOVdczVd/ep6pS9JIPJDF5NG9GN6jpdMhK6WU17mV0EXkcmAyEAq8ZYx5rtTxe4H7gUIgCxhnjNnk4VgB+PGBZ+g/eSJrW3TivlF/pqBFK56q15P67UfRM3MP3zdpj/lqB1H1a/LW7XEM6qwbNyulgkOlCV1EQoEpwKVACrBKROaXStizjDGvF7UfDrwEXO6FeKlz2RB+2ZpA5j+e5+vOLahXswY70rL5dksqm/Yc4ZlWDenfvgkdm9bTChalVFBxp4feF0g0xmwHEJHZwAjgeEI3xhwp0b4uYDwZZEk9rhgAVww46bV2UfVoF1XPW2+plFJ+wZ2E3grYVeJ5CnBe6UYicj/wEBAOXFLWiURkHDAOICYm5nRjVUopVQGPTZE0xkwxxrQHHgP+Wk6bqcaYOGNMXFRUlKfeWimlFO4l9N1AdInnrYteK89sYGQVYlJKKXUG3Enoq4COItJWRMKB0cD8kg1EpGOJp1cBWz0XolJKKXdUOoZujCkQkQnAQmzZ4nRjzEYRmQTEG2PmAxNEZAiQDxwCbvdm0EoppU7lVh26MeYL4ItSrz1V4vEfPRyXUkqp06TrxiqlVIDQhK6UUgFCjPHaHKCK31gkFdh5ht8eCaR5MBx/p9fjZHo9TtBrcbJAuB5tjDFl1n07ltCrQkTijTFxTsfhK/R6nEyvxwl6LU4W6NdDh1yUUipAaEJXSqkA4a8JfarTAfgYvR4n0+txgl6LkwX09fDLMXSllFKn8tceulJKqVI0oSulVIDw6YQuIpeLSIKIJIrI42Ucrykic4qO/yQisQ6EWW3cuB4PicgmEVkvIt+ISBsn4qwOlV2LEu2uFREjIgFbqgbuXQ8RuaHo52OjiMyq7hirkxu/KzEislRE1hT9vlzpRJweZ4zxyS/sQmDbgHbYTTPWAV1Ktfkd8HrR49HAHKfjdvh6XAzUKXp8X6BeD3euRVG7+sByYCUQ53TcDv9sdATWAI2Knjd1Om6Hr8dU4L6ix12AJKfj9sSXL/fQj299Z4w5hl1nfUSpNiOAd4oezwMGS+BuJFrp9TDGLDXG5BQ9XYlduz4QufOzAfAs8DxwtDqDc4A71+MeYIox5hCAMeZANcdYndy5HgZoUPS4IbCnGuPzGl9O6GVtfdeqvDbGmALgMNCkWqKrfu5cj5LuAr70akTOqfRaiEhvINoY83l1BuYQd342OgGdROQHEVkpIl7ZxN1HuHM9ngFuEZEU7Eqyv6+e0LzLreVzlX8RkVuAOOAip2NxgoiEAC8Bdzgcii+pgR12GYT95LZcRLoZYzKcDMpBNwEzjDEvikh/4D0R6WqMcTkdWFX4cg/dna3vjrcRkRrYj07p1RJd9XNrK8CijUb+Agw3xuRVU2zVrbJrUR/oCiwTkSSgHzA/gG+MuvOzkQLMN8bkG2N2AFuwCT4QuXM97gLmAhhjfgRqYRfu8mu+nNAr3fqu6Hnx7kjXAUtM0V2OAOTOVoC9gDewyTyQx0grvBbGmMPGmEhjTKwxJhZ7P2G4MSbemXC9zp3flU+wvXNEJBI7BLO9GmOsTu5cj2RgMICInI1N6KnVGqUX+GxCLxoTL976bjMw1xRtfSciw4uaTQOaiEgi8BBQbvmav3PzevwbqAd8KCJrRaT0D3FAcPNaBA03r8dCIF1ENgFLgUeNMQH5adbN6/EwcI+IrAM+AO4IhM6gTv1XSqkA4bM9dKWUUqdHE7pSSgUITehKKRUgNKErpVSA0ISulFIBQhO6UkoFCE3oSikVIP4fmLFHWsFjHeMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "import numpy as np \n",
    "threshold0 = np.linspace(0,0.9,100)\n",
    "prec_list = []\n",
    "acc_list = []\n",
    "\n",
    "for th in threshold0:\n",
    "    pred = prob_test[:,1] >= th \n",
    "    prec_list.append(metrics.precision_score (y_test, pred))\n",
    "    acc_list.append(metrics.accuracy_score(y_test, pred))\n",
    "plt.plot(threshold0, prec_list)\n",
    "plt.plot(threshold0, acc_list, c ='r')\n",
    "\n",
    "# Base on the plot below the model begins to overfit around 65%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Networks\n",
    "Using Keras, build a DNN that has better accuracy than LR. What is the accuracy, precision and recall and F1 score for the training and the test data? Plot the ROC curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers, layers, activations\n",
    "from tensorflow.keras import models \n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "scaler =  StandardScaler().fit(X_train)\n",
    "x_scaled_train = scaler.transform(X_train)\n",
    "x_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(400, activation = \"relu\", input_dim = 8 ))\n",
    "model.add(layers.Dense(250, kernel_regularizer = regularizers.l2(0.001), activation= 'relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(90, kernel_regularizer = regularizers.l2(0.001), activation= 'relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer=tf.keras.optimizers.Nadam(lr = 0.0000055), metrics= [\"accuracy\",\"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From /Users/fjacobo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 1.1372 - accuracy: 0.4879 - precision: 0.3402 - recall: 0.4213 - val_loss: 1.1304 - val_accuracy: 0.5455 - val_precision: 0.3365 - val_recall: 0.4930\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.1335 - accuracy: 0.4935 - precision: 0.3333 - recall: 0.3807 - val_loss: 1.1250 - val_accuracy: 0.5801 - val_precision: 0.3617 - val_recall: 0.4789\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.1256 - accuracy: 0.5438 - precision: 0.3879 - recall: 0.4213 - val_loss: 1.1200 - val_accuracy: 0.6407 - val_precision: 0.4302 - val_recall: 0.5211\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1269 - accuracy: 0.5717 - precision: 0.4118 - recall: 0.3909 - val_loss: 1.1147 - val_accuracy: 0.6883 - val_precision: 0.4930 - val_recall: 0.4930\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1204 - accuracy: 0.6201 - precision: 0.4788 - recall: 0.4010 - val_loss: 1.1096 - val_accuracy: 0.6970 - val_precision: 0.5075 - val_recall: 0.4789\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1113 - accuracy: 0.6574 - precision: 0.5468 - recall: 0.3858 - val_loss: 1.1047 - val_accuracy: 0.7100 - val_precision: 0.5333 - val_recall: 0.4507\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1087 - accuracy: 0.6648 - precision: 0.5620 - recall: 0.3909 - val_loss: 1.0999 - val_accuracy: 0.7186 - val_precision: 0.5556 - val_recall: 0.4225\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1026 - accuracy: 0.6797 - precision: 0.5912 - recall: 0.4112 - val_loss: 1.0949 - val_accuracy: 0.7229 - val_precision: 0.5660 - val_recall: 0.4225\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0991 - accuracy: 0.6853 - precision: 0.6250 - recall: 0.3553 - val_loss: 1.0901 - val_accuracy: 0.7359 - val_precision: 0.6042 - val_recall: 0.4085\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.1001 - accuracy: 0.6946 - precision: 0.6486 - recall: 0.3655 - val_loss: 1.0853 - val_accuracy: 0.7403 - val_precision: 0.6170 - val_recall: 0.4085\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0951 - accuracy: 0.6946 - precision: 0.6542 - recall: 0.3553 - val_loss: 1.0806 - val_accuracy: 0.7446 - val_precision: 0.6304 - val_recall: 0.4085\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0913 - accuracy: 0.6816 - precision: 0.6140 - recall: 0.3553 - val_loss: 1.0759 - val_accuracy: 0.7316 - val_precision: 0.6047 - val_recall: 0.3662\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0866 - accuracy: 0.7020 - precision: 0.6609 - recall: 0.3858 - val_loss: 1.0713 - val_accuracy: 0.7359 - val_precision: 0.6190 - val_recall: 0.3662\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0823 - accuracy: 0.6927 - precision: 0.6333 - recall: 0.3858 - val_loss: 1.0669 - val_accuracy: 0.7446 - val_precision: 0.6429 - val_recall: 0.3803\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.0778 - accuracy: 0.6909 - precision: 0.6566 - recall: 0.3299 - val_loss: 1.0625 - val_accuracy: 0.7532 - val_precision: 0.6591 - val_recall: 0.4085\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0718 - accuracy: 0.6927 - precision: 0.6481 - recall: 0.3553 - val_loss: 1.0580 - val_accuracy: 0.7576 - val_precision: 0.6744 - val_recall: 0.4085\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0687 - accuracy: 0.7076 - precision: 0.6923 - recall: 0.3655 - val_loss: 1.0535 - val_accuracy: 0.7576 - val_precision: 0.6744 - val_recall: 0.4085\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0669 - accuracy: 0.7114 - precision: 0.7059 - recall: 0.3655 - val_loss: 1.0490 - val_accuracy: 0.7749 - val_precision: 0.7436 - val_recall: 0.4085\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.7188 - precision: 0.7347 - recall: 0.3655 - val_loss: 1.0447 - val_accuracy: 0.7706 - val_precision: 0.7250 - val_recall: 0.4085\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0569 - accuracy: 0.7337 - precision: 0.7455 - recall: 0.4162 - val_loss: 1.0404 - val_accuracy: 0.7706 - val_precision: 0.7250 - val_recall: 0.4085\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0523 - accuracy: 0.7318 - precision: 0.7431 - recall: 0.4112 - val_loss: 1.0361 - val_accuracy: 0.7749 - val_precision: 0.7436 - val_recall: 0.4085\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.7337 - precision: 0.7547 - recall: 0.4061 - val_loss: 1.0321 - val_accuracy: 0.7792 - val_precision: 0.7500 - val_recall: 0.4225\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0449 - accuracy: 0.7244 - precision: 0.7290 - recall: 0.3959 - val_loss: 1.0278 - val_accuracy: 0.7835 - val_precision: 0.7692 - val_recall: 0.4225\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.7337 - precision: 0.7547 - recall: 0.4061 - val_loss: 1.0239 - val_accuracy: 0.7835 - val_precision: 0.7561 - val_recall: 0.4366\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.7318 - precision: 0.7431 - recall: 0.4112 - val_loss: 1.0196 - val_accuracy: 0.7835 - val_precision: 0.7561 - val_recall: 0.4366\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0349 - accuracy: 0.7132 - precision: 0.7009 - recall: 0.3807 - val_loss: 1.0156 - val_accuracy: 0.7835 - val_precision: 0.7561 - val_recall: 0.4366\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0272 - accuracy: 0.7393 - precision: 0.7436 - recall: 0.4416 - val_loss: 1.0116 - val_accuracy: 0.7879 - val_precision: 0.7619 - val_recall: 0.4507\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0263 - accuracy: 0.7281 - precision: 0.7179 - recall: 0.4264 - val_loss: 1.0075 - val_accuracy: 0.7835 - val_precision: 0.7442 - val_recall: 0.4507\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0235 - accuracy: 0.7579 - precision: 0.7815 - recall: 0.4721 - val_loss: 1.0037 - val_accuracy: 0.7879 - val_precision: 0.7500 - val_recall: 0.4648\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0174 - accuracy: 0.7356 - precision: 0.7273 - recall: 0.4467 - val_loss: 0.9996 - val_accuracy: 0.7879 - val_precision: 0.7500 - val_recall: 0.4648\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0173 - accuracy: 0.7300 - precision: 0.7321 - recall: 0.4162 - val_loss: 0.9959 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.7430 - precision: 0.7479 - recall: 0.4518 - val_loss: 0.9922 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0075 - accuracy: 0.7486 - precision: 0.7627 - recall: 0.4569 - val_loss: 0.9886 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0060 - accuracy: 0.7318 - precision: 0.7227 - recall: 0.4365 - val_loss: 0.9849 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.0012 - accuracy: 0.7412 - precision: 0.7458 - recall: 0.4467 - val_loss: 0.9815 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9909 - accuracy: 0.7561 - precision: 0.7750 - recall: 0.4721 - val_loss: 0.9779 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9919 - accuracy: 0.7654 - precision: 0.7630 - recall: 0.5228 - val_loss: 0.9743 - val_accuracy: 0.7922 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9895 - accuracy: 0.7393 - precision: 0.7244 - recall: 0.4670 - val_loss: 0.9709 - val_accuracy: 0.7965 - val_precision: 0.7609 - val_recall: 0.4930\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9904 - accuracy: 0.7412 - precision: 0.7266 - recall: 0.4721 - val_loss: 0.9678 - val_accuracy: 0.7965 - val_precision: 0.7609 - val_recall: 0.4930\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9842 - accuracy: 0.7356 - precision: 0.7132 - recall: 0.4670 - val_loss: 0.9647 - val_accuracy: 0.7922 - val_precision: 0.7447 - val_recall: 0.4930\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9807 - accuracy: 0.7374 - precision: 0.7258 - recall: 0.4569 - val_loss: 0.9616 - val_accuracy: 0.7922 - val_precision: 0.7447 - val_recall: 0.4930\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.7561 - precision: 0.7661 - recall: 0.4822 - val_loss: 0.9587 - val_accuracy: 0.7965 - val_precision: 0.7500 - val_recall: 0.5070\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.7430 - precision: 0.7218 - recall: 0.4873 - val_loss: 0.9555 - val_accuracy: 0.7965 - val_precision: 0.7500 - val_recall: 0.5070\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9724 - accuracy: 0.7486 - precision: 0.7385 - recall: 0.4873 - val_loss: 0.9526 - val_accuracy: 0.7965 - val_precision: 0.7500 - val_recall: 0.5070\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9670 - accuracy: 0.7449 - precision: 0.7381 - recall: 0.4721 - val_loss: 0.9497 - val_accuracy: 0.7965 - val_precision: 0.7500 - val_recall: 0.5070\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9678 - accuracy: 0.7616 - precision: 0.7594 - recall: 0.5127 - val_loss: 0.9469 - val_accuracy: 0.7965 - val_precision: 0.7500 - val_recall: 0.5070\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.7579 - precision: 0.7557 - recall: 0.5025 - val_loss: 0.9442 - val_accuracy: 0.8009 - val_precision: 0.7551 - val_recall: 0.5211\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9628 - accuracy: 0.7486 - precision: 0.7385 - recall: 0.4873 - val_loss: 0.9416 - val_accuracy: 0.8009 - val_precision: 0.7551 - val_recall: 0.5211\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9625 - accuracy: 0.7449 - precision: 0.7143 - recall: 0.5076 - val_loss: 0.9392 - val_accuracy: 0.8009 - val_precision: 0.7551 - val_recall: 0.5211\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.7486 - precision: 0.7214 - recall: 0.5127 - val_loss: 0.9366 - val_accuracy: 0.8009 - val_precision: 0.7551 - val_recall: 0.5211\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9510 - accuracy: 0.7635 - precision: 0.7536 - recall: 0.5279 - val_loss: 0.9340 - val_accuracy: 0.8009 - val_precision: 0.7551 - val_recall: 0.5211\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9496 - accuracy: 0.7635 - precision: 0.7397 - recall: 0.5482 - val_loss: 0.9317 - val_accuracy: 0.8009 - val_precision: 0.7451 - val_recall: 0.5352\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.7654 - precision: 0.7448 - recall: 0.5482 - val_loss: 0.9293 - val_accuracy: 0.7965 - val_precision: 0.7308 - val_recall: 0.5352\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9426 - accuracy: 0.7579 - precision: 0.7190 - recall: 0.5584 - val_loss: 0.9271 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9396 - accuracy: 0.7709 - precision: 0.7643 - recall: 0.5431 - val_loss: 0.9248 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9360 - accuracy: 0.7709 - precision: 0.7569 - recall: 0.5533 - val_loss: 0.9226 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9289 - accuracy: 0.7654 - precision: 0.7518 - recall: 0.5381 - val_loss: 0.9205 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9305 - accuracy: 0.7654 - precision: 0.7290 - recall: 0.5736 - val_loss: 0.9184 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9276 - accuracy: 0.7765 - precision: 0.7730 - recall: 0.5533 - val_loss: 0.9165 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.7728 - precision: 0.7551 - recall: 0.5635 - val_loss: 0.9144 - val_accuracy: 0.7922 - val_precision: 0.7170 - val_recall: 0.5352\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9209 - accuracy: 0.7672 - precision: 0.7400 - recall: 0.5635 - val_loss: 0.9125 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.7691 - precision: 0.7483 - recall: 0.5584 - val_loss: 0.9105 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9205 - accuracy: 0.7635 - precision: 0.7303 - recall: 0.5635 - val_loss: 0.9087 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9259 - accuracy: 0.7635 - precision: 0.7333 - recall: 0.5584 - val_loss: 0.9070 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9146 - accuracy: 0.7672 - precision: 0.7338 - recall: 0.5736 - val_loss: 0.9055 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9199 - accuracy: 0.7672 - precision: 0.7250 - recall: 0.5888 - val_loss: 0.9038 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9128 - accuracy: 0.7747 - precision: 0.7436 - recall: 0.5888 - val_loss: 0.9022 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9068 - accuracy: 0.7728 - precision: 0.7329 - recall: 0.5990 - val_loss: 0.9007 - val_accuracy: 0.7879 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9107 - accuracy: 0.7616 - precision: 0.7197 - recall: 0.5736 - val_loss: 0.8991 - val_accuracy: 0.7922 - val_precision: 0.7091 - val_recall: 0.5493\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9113 - accuracy: 0.7561 - precision: 0.7230 - recall: 0.5431 - val_loss: 0.8977 - val_accuracy: 0.7879 - val_precision: 0.6964 - val_recall: 0.5493\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9045 - accuracy: 0.7635 - precision: 0.7244 - recall: 0.5736 - val_loss: 0.8963 - val_accuracy: 0.7879 - val_precision: 0.6964 - val_recall: 0.5493\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.7654 - precision: 0.7205 - recall: 0.5888 - val_loss: 0.8948 - val_accuracy: 0.7879 - val_precision: 0.6964 - val_recall: 0.5493\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8988 - accuracy: 0.7784 - precision: 0.7532 - recall: 0.5888 - val_loss: 0.8934 - val_accuracy: 0.7922 - val_precision: 0.7091 - val_recall: 0.5493\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8987 - accuracy: 0.7561 - precision: 0.7115 - recall: 0.5635 - val_loss: 0.8922 - val_accuracy: 0.7879 - val_precision: 0.6964 - val_recall: 0.5493\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8951 - accuracy: 0.7709 - precision: 0.7372 - recall: 0.5838 - val_loss: 0.8908 - val_accuracy: 0.7922 - val_precision: 0.7018 - val_recall: 0.5634\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.7728 - precision: 0.7301 - recall: 0.6041 - val_loss: 0.8896 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8968 - accuracy: 0.7728 - precision: 0.7483 - recall: 0.5736 - val_loss: 0.8884 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.7709 - precision: 0.7229 - recall: 0.6091 - val_loss: 0.8872 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.7691 - precision: 0.7296 - recall: 0.5888 - val_loss: 0.8861 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.7616 - precision: 0.7143 - recall: 0.5838 - val_loss: 0.8848 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8968 - accuracy: 0.7709 - precision: 0.7284 - recall: 0.5990 - val_loss: 0.8838 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8896 - accuracy: 0.7635 - precision: 0.7134 - recall: 0.5939 - val_loss: 0.8827 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8848 - accuracy: 0.7784 - precision: 0.7500 - recall: 0.5939 - val_loss: 0.8817 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8891 - accuracy: 0.7598 - precision: 0.7024 - recall: 0.5990 - val_loss: 0.8806 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.7709 - precision: 0.7403 - recall: 0.5787 - val_loss: 0.8796 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8830 - accuracy: 0.7672 - precision: 0.7222 - recall: 0.5939 - val_loss: 0.8786 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8795 - accuracy: 0.7579 - precision: 0.7006 - recall: 0.5939 - val_loss: 0.8777 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8786 - accuracy: 0.7803 - precision: 0.7453 - recall: 0.6091 - val_loss: 0.8768 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8768 - accuracy: 0.7672 - precision: 0.7222 - recall: 0.5939 - val_loss: 0.8759 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8729 - accuracy: 0.7728 - precision: 0.7273 - recall: 0.6091 - val_loss: 0.8750 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.7654 - precision: 0.7101 - recall: 0.6091 - val_loss: 0.8740 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.7728 - precision: 0.7329 - recall: 0.5990 - val_loss: 0.8734 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8672 - accuracy: 0.7877 - precision: 0.7546 - recall: 0.6244 - val_loss: 0.8725 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8627 - accuracy: 0.7821 - precision: 0.7500 - recall: 0.6091 - val_loss: 0.8716 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.7709 - precision: 0.7312 - recall: 0.5939 - val_loss: 0.8709 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8691 - accuracy: 0.7672 - precision: 0.7278 - recall: 0.5838 - val_loss: 0.8701 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8664 - accuracy: 0.7728 - precision: 0.7301 - recall: 0.6041 - val_loss: 0.8694 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8686 - accuracy: 0.7747 - precision: 0.7289 - recall: 0.6142 - val_loss: 0.8688 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8619 - accuracy: 0.7914 - precision: 0.7576 - recall: 0.6345 - val_loss: 0.8681 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8638 - accuracy: 0.7803 - precision: 0.7423 - recall: 0.6142 - val_loss: 0.8675 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8620 - accuracy: 0.7654 - precision: 0.7126 - recall: 0.6041 - val_loss: 0.8667 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8596 - accuracy: 0.7803 - precision: 0.7365 - recall: 0.6244 - val_loss: 0.8662 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8619 - accuracy: 0.7654 - precision: 0.7126 - recall: 0.6041 - val_loss: 0.8657 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8567 - accuracy: 0.7691 - precision: 0.7212 - recall: 0.6041 - val_loss: 0.8650 - val_accuracy: 0.7879 - val_precision: 0.6897 - val_recall: 0.5634\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8606 - accuracy: 0.7765 - precision: 0.7452 - recall: 0.5939 - val_loss: 0.8643 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8515 - accuracy: 0.7709 - precision: 0.7176 - recall: 0.6193 - val_loss: 0.8637 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8584 - accuracy: 0.7747 - precision: 0.7262 - recall: 0.6193 - val_loss: 0.8632 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8583 - accuracy: 0.7654 - precision: 0.7076 - recall: 0.6142 - val_loss: 0.8625 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8585 - accuracy: 0.7821 - precision: 0.7410 - recall: 0.6244 - val_loss: 0.8620 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8583 - accuracy: 0.7672 - precision: 0.7045 - recall: 0.6294 - val_loss: 0.8614 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8481 - accuracy: 0.7803 - precision: 0.7423 - recall: 0.6142 - val_loss: 0.8607 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.7709 - precision: 0.7284 - recall: 0.5990 - val_loss: 0.8603 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8509 - accuracy: 0.7821 - precision: 0.7326 - recall: 0.6396 - val_loss: 0.8598 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.7672 - precision: 0.7093 - recall: 0.6193 - val_loss: 0.8592 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.7709 - precision: 0.7229 - recall: 0.6091 - val_loss: 0.8586 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8524 - accuracy: 0.7728 - precision: 0.7246 - recall: 0.6142 - val_loss: 0.8582 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.7728 - precision: 0.7193 - recall: 0.6244 - val_loss: 0.8578 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8456 - accuracy: 0.7803 - precision: 0.7337 - recall: 0.6294 - val_loss: 0.8574 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8503 - accuracy: 0.7709 - precision: 0.7202 - recall: 0.6142 - val_loss: 0.8568 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.7803 - precision: 0.7257 - recall: 0.6447 - val_loss: 0.8564 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8418 - accuracy: 0.7784 - precision: 0.7349 - recall: 0.6193 - val_loss: 0.8559 - val_accuracy: 0.7835 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8382 - accuracy: 0.7709 - precision: 0.7229 - recall: 0.6091 - val_loss: 0.8554 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8503 - accuracy: 0.7747 - precision: 0.7209 - recall: 0.6294 - val_loss: 0.8550 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8439 - accuracy: 0.7709 - precision: 0.7202 - recall: 0.6142 - val_loss: 0.8546 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8397 - accuracy: 0.7803 - precision: 0.7394 - recall: 0.6193 - val_loss: 0.8542 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8372 - accuracy: 0.7728 - precision: 0.7219 - recall: 0.6193 - val_loss: 0.8537 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8387 - accuracy: 0.7803 - precision: 0.7257 - recall: 0.6447 - val_loss: 0.8533 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8384 - accuracy: 0.7765 - precision: 0.7200 - recall: 0.6396 - val_loss: 0.8529 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8316 - accuracy: 0.7747 - precision: 0.7317 - recall: 0.6091 - val_loss: 0.8525 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8282 - accuracy: 0.7765 - precision: 0.7305 - recall: 0.6193 - val_loss: 0.8522 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8269 - accuracy: 0.7803 - precision: 0.7257 - recall: 0.6447 - val_loss: 0.8516 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8283 - accuracy: 0.7821 - precision: 0.7353 - recall: 0.6345 - val_loss: 0.8512 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8354 - accuracy: 0.7747 - precision: 0.7289 - recall: 0.6142 - val_loss: 0.8509 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.7821 - precision: 0.7410 - recall: 0.6244 - val_loss: 0.8505 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8316 - accuracy: 0.7803 - precision: 0.7257 - recall: 0.6447 - val_loss: 0.8501 - val_accuracy: 0.7879 - val_precision: 0.6833 - val_recall: 0.5775\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8311 - accuracy: 0.7803 - precision: 0.7207 - recall: 0.6548 - val_loss: 0.8497 - val_accuracy: 0.7922 - val_precision: 0.6949 - val_recall: 0.5775\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.7765 - precision: 0.7151 - recall: 0.6497 - val_loss: 0.8493 - val_accuracy: 0.7922 - val_precision: 0.6949 - val_recall: 0.5775\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8251 - accuracy: 0.7598 - precision: 0.6932 - recall: 0.6193 - val_loss: 0.8490 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8261 - accuracy: 0.7858 - precision: 0.7384 - recall: 0.6447 - val_loss: 0.8486 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8348 - accuracy: 0.7896 - precision: 0.7471 - recall: 0.6447 - val_loss: 0.8484 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8266 - accuracy: 0.7877 - precision: 0.7427 - recall: 0.6447 - val_loss: 0.8480 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8214 - accuracy: 0.7840 - precision: 0.7314 - recall: 0.6497 - val_loss: 0.8477 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8270 - accuracy: 0.7784 - precision: 0.7241 - recall: 0.6396 - val_loss: 0.8473 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8293 - accuracy: 0.7728 - precision: 0.7193 - recall: 0.6244 - val_loss: 0.8469 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8239 - accuracy: 0.7803 - precision: 0.7365 - recall: 0.6244 - val_loss: 0.8465 - val_accuracy: 0.7965 - val_precision: 0.7000 - val_recall: 0.5915\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8277 - accuracy: 0.7765 - precision: 0.7278 - recall: 0.6244 - val_loss: 0.8462 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8221 - accuracy: 0.7877 - precision: 0.7399 - recall: 0.6497 - val_loss: 0.8459 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8218 - accuracy: 0.7821 - precision: 0.7353 - recall: 0.6345 - val_loss: 0.8456 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8281 - accuracy: 0.7896 - precision: 0.7386 - recall: 0.6599 - val_loss: 0.8453 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8177 - accuracy: 0.7821 - precision: 0.7353 - recall: 0.6345 - val_loss: 0.8450 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8171 - accuracy: 0.7914 - precision: 0.7457 - recall: 0.6548 - val_loss: 0.8446 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8271 - accuracy: 0.7691 - precision: 0.7086 - recall: 0.6294 - val_loss: 0.8443 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8190 - accuracy: 0.7747 - precision: 0.7262 - recall: 0.6193 - val_loss: 0.8440 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8271 - accuracy: 0.7747 - precision: 0.7135 - recall: 0.6447 - val_loss: 0.8436 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8150 - accuracy: 0.7765 - precision: 0.7200 - recall: 0.6396 - val_loss: 0.8433 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.7914 - precision: 0.7401 - recall: 0.6650 - val_loss: 0.8429 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8145 - accuracy: 0.7914 - precision: 0.7640 - recall: 0.6244 - val_loss: 0.8426 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8137 - accuracy: 0.7858 - precision: 0.7356 - recall: 0.6497 - val_loss: 0.8422 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8110 - accuracy: 0.7840 - precision: 0.7341 - recall: 0.6447 - val_loss: 0.8420 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.7803 - precision: 0.7337 - recall: 0.6294 - val_loss: 0.8417 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8086 - accuracy: 0.7896 - precision: 0.7471 - recall: 0.6447 - val_loss: 0.8414 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8122 - accuracy: 0.7821 - precision: 0.7326 - recall: 0.6396 - val_loss: 0.8411 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.7803 - precision: 0.7232 - recall: 0.6497 - val_loss: 0.8409 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8096 - accuracy: 0.7914 - precision: 0.7515 - recall: 0.6447 - val_loss: 0.8405 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8085 - accuracy: 0.7858 - precision: 0.7470 - recall: 0.6294 - val_loss: 0.8402 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8081 - accuracy: 0.7803 - precision: 0.7310 - recall: 0.6345 - val_loss: 0.8399 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8165 - accuracy: 0.7803 - precision: 0.7207 - recall: 0.6548 - val_loss: 0.8396 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8076 - accuracy: 0.7840 - precision: 0.7263 - recall: 0.6599 - val_loss: 0.8393 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8057 - accuracy: 0.7691 - precision: 0.7110 - recall: 0.6244 - val_loss: 0.8390 - val_accuracy: 0.8009 - val_precision: 0.7049 - val_recall: 0.6056\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8088 - accuracy: 0.7858 - precision: 0.7384 - recall: 0.6447 - val_loss: 0.8388 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8105 - accuracy: 0.7840 - precision: 0.7341 - recall: 0.6447 - val_loss: 0.8385 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8082 - accuracy: 0.7709 - precision: 0.7126 - recall: 0.6294 - val_loss: 0.8383 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8033 - accuracy: 0.7896 - precision: 0.7414 - recall: 0.6548 - val_loss: 0.8380 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8042 - accuracy: 0.7765 - precision: 0.7251 - recall: 0.6294 - val_loss: 0.8377 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8047 - accuracy: 0.7821 - precision: 0.7299 - recall: 0.6447 - val_loss: 0.8374 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.7784 - precision: 0.7241 - recall: 0.6396 - val_loss: 0.8371 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8132 - accuracy: 0.7747 - precision: 0.7235 - recall: 0.6244 - val_loss: 0.8368 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8111 - accuracy: 0.7784 - precision: 0.7216 - recall: 0.6447 - val_loss: 0.8364 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.7803 - precision: 0.7310 - recall: 0.6345 - val_loss: 0.8362 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8032 - accuracy: 0.7840 - precision: 0.7368 - recall: 0.6396 - val_loss: 0.8359 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8024 - accuracy: 0.7952 - precision: 0.7486 - recall: 0.6650 - val_loss: 0.8357 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.7896 - precision: 0.7442 - recall: 0.6497 - val_loss: 0.8354 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7969 - accuracy: 0.7840 - precision: 0.7425 - recall: 0.6294 - val_loss: 0.8352 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8000 - accuracy: 0.7803 - precision: 0.7257 - recall: 0.6447 - val_loss: 0.8349 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7928 - accuracy: 0.7896 - precision: 0.7414 - recall: 0.6548 - val_loss: 0.8347 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.7784 - precision: 0.7216 - recall: 0.6447 - val_loss: 0.8345 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7965 - accuracy: 0.7877 - precision: 0.7345 - recall: 0.6599 - val_loss: 0.8341 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7923 - accuracy: 0.7747 - precision: 0.7135 - recall: 0.6447 - val_loss: 0.8338 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7940 - accuracy: 0.7747 - precision: 0.7235 - recall: 0.6244 - val_loss: 0.8334 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7930 - accuracy: 0.7933 - precision: 0.7443 - recall: 0.6650 - val_loss: 0.8330 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7932 - accuracy: 0.7803 - precision: 0.7232 - recall: 0.6497 - val_loss: 0.8328 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7923 - accuracy: 0.7840 - precision: 0.7238 - recall: 0.6650 - val_loss: 0.8324 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7970 - accuracy: 0.7784 - precision: 0.7349 - recall: 0.6193 - val_loss: 0.8322 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7881 - accuracy: 0.7896 - precision: 0.7414 - recall: 0.6548 - val_loss: 0.8320 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.7970 - precision: 0.7588 - recall: 0.6548 - val_loss: 0.8317 - val_accuracy: 0.7965 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7935 - accuracy: 0.7858 - precision: 0.7470 - recall: 0.6294 - val_loss: 0.8316 - val_accuracy: 0.7922 - val_precision: 0.6825 - val_recall: 0.6056\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7961 - accuracy: 0.7784 - precision: 0.7216 - recall: 0.6447 - val_loss: 0.8312 - val_accuracy: 0.7922 - val_precision: 0.6825 - val_recall: 0.6056\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.7858 - precision: 0.7440 - recall: 0.6345 - val_loss: 0.8310 - val_accuracy: 0.7922 - val_precision: 0.6825 - val_recall: 0.6056\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.7747 - precision: 0.7209 - recall: 0.6294 - val_loss: 0.8308 - val_accuracy: 0.7922 - val_precision: 0.6825 - val_recall: 0.6056\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7880 - accuracy: 0.7952 - precision: 0.7377 - recall: 0.6853 - val_loss: 0.8305 - val_accuracy: 0.7922 - val_precision: 0.6825 - val_recall: 0.6056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbea84bca90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_scaled_train, y_train, epochs =200, batch_size = 15, validation_data = (x_scaled_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Metrics:\n",
      "WARNING:tensorflow:From <ipython-input-11-a56df005f7d4>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       160\n",
      "           1       0.68      0.61      0.64        71\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.76      0.74      0.75       231\n",
      "weighted avg       0.79      0.79      0.79       231\n",
      "\n",
      "Train Data Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       340\n",
      "           1       0.74      0.64      0.69       197\n",
      "\n",
      "    accuracy                           0.79       537\n",
      "   macro avg       0.77      0.76      0.76       537\n",
      "weighted avg       0.78      0.79      0.78       537\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-11-a56df005f7d4>:11: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbef879b950>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQFklEQVR4nO3da4xc9XnH8e+DKY3aYmhrR3J8yRLVSNnQqkErDIrUUEEqgxT7RdrIRihN6+IkLVElokpUVICcN6FRUiWSlcRNEUkkLk5ehJXi1FVbEBKKXS/CIXgR0cZcvI5VNoTCi4iAlacvZhZNhl3PWe+ZOTP/+X6kleby985zWO+Px8+5RWYiSRp9FzRdgCSpHga6JBXCQJekQhjoklQIA12SCnFhUx+8bt26nJiYaOrjJWkkPfHEEz/LzPVLvddYoE9MTDAzM9PUx0vSSIqIF5Z7z5GLJBXCQJekQhjoklQIA12SCmGgS1IhegZ6RNwbES9FxNPLvB8R8eWImIuIpyLiyvrLlCT1UqVDvw/Yfo73bwC2tr/2Al9ZfVmSpJXqeRx6Zj4WERPnWLIT+Ga2rsN7JCIujYgNmXmmriIlaVTdf/RFHj5++tdem3zXWu768Ptq/6w6ZugbgVMdz+fbr71NROyNiJmImFlYWKjhoyVpuD18/DSzZ14byGcN9EzRzDwAHACYmpryzhqSxsLkhrU89Ilr+v45dQT6aWBzx/NN7dckaaQtNS5ZqdkzrzG5YW1NFZ1bHSOXaeBj7aNdrgZedX4uqQR1jEsmN6xl5x8vOYWuXc8OPSIeAK4F1kXEPHAX8BsAmflV4BBwIzAH/AL4q34VK0mDNqhxSR2qHOWyu8f7CfxdbRVJUoc6xh7na5Djkjp4pqikoTbIo0S6DXJcUofGrocuSVWN0tijSQa6pNrVOSYZtbFHkxy5SKpdnWOSURt7NMkOXRphTe4wPJfFrtoxyWDZoUsjrMkdhudiV90MO3RpxNkJa5GBLtVo0CMQdxiqkyMXqUaDHoE42lAnO3SpZo5A1BQDXarB4qjFEYia5MhFqkFnmDsCUVPs0KWaOGpR0wx0qYJeR684atEwcOQiVdDr6BVHLRoGduhSRY5UNOwMdBXLK/5p3DhyUbG84p/GjR26itHdkXvFP40bO3QVo7sjt6vWuLFDV1HsyDXO7NAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSITxsUSPPm0tILXboGnneXEJqsUNXZYO+o31VnuIvtdihq7JB39G+KjtzqaVShx4R24EvAWuAr2fm57re3wJ8A7i0veb2zDxUb6kaBnbC0vDqGegRsQbYD3wImAeORcR0Zs52LPsn4GBmfiUiJoFDwEQf6tWAdY5Z3OkoDbcqI5ergLnMPJmZbwAPAju71iSw+Jt+CfDT+kpUkzrHLI42pOFWZeSyETjV8Xwe2Na15m7gPyLi08BvA9cv9Y0iYi+wF2DLli0rrVUNccwijYa6jnLZDdyXmV+IiGuAb0XEFZn5q85FmXkAOAAwNTWVNX22zkPVI1Ycs0ijo8rI5TSwueP5pvZrnfYABwEy8wfAO4B1dRSo/qh6xIpjFml0VOnQjwFbI+IyWkG+C7ipa82LwHXAfRHxXlqBvlBnoaqfoxSpLD079Mw8C9wKHAaeoXU0y4mI2BcRO9rLPgPcEhE/BB4APp6ZjlQkaYAqzdDbx5Qf6nrtzo7Hs8AH6i1NkrQSnikqSYXwWi5jxisTSuWyQx8zXplQKpcdeuG6jzf3yoRSuezQC9d9vLmduVQuO/QxYEcujQcDvSBLnc7vzk9pfDhyKchSp/M7YpHGhx16YRyvSOPLDl2SCmGgS1IhDHRJKoQz9BG23ElDksaTHfoI86QhSZ3s0IdYr9vEeRq/pE526EOs123i7MgldbJDH3J24JKqMtAbdq6xijs5Ja2EI5eGnWus4khF0krYoQ8BxyqS6mCgN8RbwUmqmyOXhngrOEl1s0NvkKMWSXUy0PtsuaNYHLVIqpsjlz5b7igWRy2S6maHPgCOViQNgh26JBXCQJekQjhy6ROPM5c0aHbofeJx5pIGrVKgR8T2iHg2IuYi4vZl1nw0ImYj4kRE3F9vmaNpcWfoTdu2NF2KpDHQc+QSEWuA/cCHgHngWERMZ+Zsx5qtwD8CH8jMVyLinf0qeBj0uvEEeJy5pMGr0qFfBcxl5snMfAN4ENjZteYWYH9mvgKQmS/VW+Zw6XXjCfA4c0mDV2Wn6EbgVMfzeWBb15rLASLicWANcHdm/nv3N4qIvcBegC1bRnsM4bHlkoZNXTtFLwS2AtcCu4F/jYhLuxdl5oHMnMrMqfXr19f00ZIkqBbop4HNHc83tV/rNA9MZ+abmfkc8GNaAS9JGpAqgX4M2BoRl0XERcAuYLprzXdpdedExDpaI5iT9ZUpSeqlZ6Bn5lngVuAw8AxwMDNPRMS+iNjRXnYYeDkiZoFHgH/IzJf7VbQk6e0qnSmamYeAQ12v3dnxOIHb2l+SpAZ4pqgkFcJruayA12eRNMzs0FfA67NIGmZ26Evodds4TyiSNIzs0JfgbeMkjSI79GXYiUsaNXboklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEKM9YlFvU7xl6RRMtYduqf4SyrJWHfo4Cn+ksoxloHudc0llWgsRy5e11xSicayQwdHLZLKM5YduiSVyECXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVIhKgR4R2yPi2YiYi4jbz7HuIxGRETFVX4mSpCp6BnpErAH2AzcAk8DuiJhcYt3FwN8DR+suUpLUW5UO/SpgLjNPZuYbwIPAziXWfRa4B3i9xvokSRVVCfSNwKmO5/Pt194SEVcCmzPze+f6RhGxNyJmImJmYWFhxcXW4f6jL3L0uZ838tmS1E+r3ikaERcAXwQ+02ttZh7IzKnMnFq/fv1qP/q8LN4U2htbSCpNlUA/DWzueL6p/dqii4ErgEcj4nngamB6mHeMbrvs97hp25amy5CkWlUJ9GPA1oi4LCIuAnYB04tvZuarmbkuMycycwI4AuzIzJm+VCxJWlLPQM/Ms8CtwGHgGeBgZp6IiH0RsaPfBUqSqql0T9HMPAQc6nrtzmXWXrv6siRJK+WZopJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEqXctllN1/9MW3roEOMHvmNSY3rG2wIknqj+I79IePn2b2zGtvPZ/csNabW0gqUrEd+mJnvtiRP/SJa5ouSZL6qtgOvTPM7cgljYNiO3TAzlzSWCm2Q5ekcWOgS1IhDHRJKkRxM/Tuo1skaVwU16F7dIukcVVchw4e3SJpPBXXoUvSuDLQJakQBrokFaKYGbpHt0gad8V06B7dImncFdOhg0e3SBpvxXTokjTuDHRJKkSlkUtEbAe+BKwBvp6Zn+t6/zbgb4CzwALw15n5Qs21Am+/pdwid4ZKGnc9O/SIWAPsB24AJoHdETHZtexJYCoz/wj4DvDPdRe6qPuWcovcGSpp3FXp0K8C5jLzJEBEPAjsBGYXF2TmIx3rjwA311lkN3d+StLbVZmhbwROdTyfb7+2nD3A95d6IyL2RsRMRMwsLCxUr1KS1FOtO0Uj4mZgCvj8Uu9n5oHMnMrMqfXr19f50ZI09qqMXE4Dmzueb2q/9msi4nrgDuCDmfnLesqTJFVVpUM/BmyNiMsi4iJgFzDduSAi3g98DdiRmS/VX6YkqZeegZ6ZZ4FbgcPAM8DBzDwREfsiYkd72eeB3wG+HRHHI2J6mW8nSeqTSsehZ+Yh4FDXa3d2PL6+5rokSSvkmaKSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBWiUqBHxPaIeDYi5iLi9iXe/82IeKj9/tGImKi9UknSOfUM9IhYA+wHbgAmgd0RMdm1bA/wSmb+AfAvwD11FypJOrcqHfpVwFxmnszMN4AHgZ1da3YC32g//g5wXUREfWVKknq5sMKajcCpjufzwLbl1mTm2Yh4Ffh94GediyJiL7AXYMuWLedV8OS71p7Xn5Ok0lUJ9Npk5gHgAMDU1FSez/e468Pvq7UmSSpFlZHLaWBzx/NN7deWXBMRFwKXAC/XUaAkqZoqgX4M2BoRl0XERcAuYLprzTTwl+3Hfw78d2aeVwcuSTo/PUcu7Zn4rcBhYA1wb2aeiIh9wExmTgP/BnwrIuaAn9MKfUnSAFWaoWfmIeBQ12t3djx+HfiLekuTJK2EZ4pKUiEMdEkqhIEuSYUw0CWpENHU0YURsQC8cJ5/fB1dZ6GOAbd5PLjN42E12/zuzFy/1BuNBfpqRMRMZk41Xccguc3jwW0eD/3aZkcuklQIA12SCjGqgX6g6QIa4DaPB7d5PPRlm0dyhi5JertR7dAlSV0MdEkqxFAH+jjenLrCNt8WEbMR8VRE/FdEvLuJOuvUa5s71n0kIjIiRv4QtyrbHBEfbf+sT0TE/YOusW4V/m5viYhHIuLJ9t/vG5uosy4RcW9EvBQRTy/zfkTEl9v/PZ6KiCtX/aGZOZRftC7V+xPgPcBFwA+Bya41fwt8tf14F/BQ03UPYJv/FPit9uNPjcM2t9ddDDwGHAGmmq57AD/nrcCTwO+2n7+z6boHsM0HgE+1H08Czzdd9yq3+U+AK4Gnl3n/RuD7QABXA0dX+5nD3KGP482pe25zZj6Smb9oPz1C6w5So6zKzxngs8A9wOuDLK5PqmzzLcD+zHwFIDNfGnCNdauyzQks3jT4EuCnA6yvdpn5GK37QyxnJ/DNbDkCXBoRG1bzmcMc6EvdnHrjcmsy8yyweHPqUVVlmzvtofV/+FHWc5vb/xTdnJnfG2RhfVTl53w5cHlEPB4RRyJi+8Cq648q23w3cHNEzNO6/8KnB1NaY1b6+97TQG8SrfpExM3AFPDBpmvpp4i4APgi8PGGSxm0C2mNXa6l9a+wxyLiDzPz/5osqs92A/dl5hci4hpad0G7IjN/1XRho2KYO/RxvDl1lW0mIq4H7gB2ZOYvB1Rbv/Ta5ouBK4BHI+J5WrPG6RHfMVrl5zwPTGfmm5n5HPBjWgE/qqps8x7gIEBm/gB4B62LWJWq0u/7SgxzoI/jzal7bnNEvB/4Gq0wH/W5KvTY5sx8NTPXZeZEZk7Q2m+wIzNnmim3FlX+bn+XVndORKyjNYI5OcAa61Zlm18ErgOIiPfSCvSFgVY5WNPAx9pHu1wNvJqZZ1b1HZveE9xjL/GNtDqTnwB3tF/bR+sXGlo/8G8Dc8D/AO9puuYBbPN/Av8LHG9/TTddc7+3uWvto4z4US4Vf85Ba9Q0C/wI2NV0zQPY5kngcVpHwBwH/qzpmle5vQ8AZ4A3af2Law/wSeCTHT/j/e3/Hj+q4++1p/5LUiGGeeQiSVoBA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQV4v8BzvLB8VmRnYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the accuracy, precision and recall and F1 score for the training and the test data?\n",
    "print(\"Test Data Metrics:\")\n",
    "pred_test1 = model.predict_classes(x_scaled_test)\n",
    "print(classification_report(y_test,pred_test1))\n",
    "\n",
    "print('Train Data Metrics:')\n",
    "pred_train1 = model.predict_classes(x_scaled_train)\n",
    "print(classification_report(y_train, pred_train1))\n",
    "\n",
    "# ROC Curve\n",
    "DNN_prob = model.predict_proba(x_scaled_test)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, DNN_prob[:,:1])\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the test precision curve  and accuracy curve for decision thresholds between 0.1 to 1 with a step of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe8849ad50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbef8799ad0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTTING THE PRECISION CURVE AND ACCURACY CURVE\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "thresholds = np.linspace(0, 0.9, 100)\n",
    "precision_list  = []\n",
    "accuracy_list = []\n",
    "\n",
    "for th in thresholds:\n",
    "    pred1 = prob_test[:,1] >= th\n",
    "    precision_list.append(metrics.precision_score(y_test, pred1))\n",
    "    accuracy_list.append(metrics.accuracy_score(y_test, pred1))\n",
    "plt.plot(thresholds, precision_list)\n",
    "plt.plot(thresholds, accuracy_list, c = 'g')\n",
    "\n",
    "# At around 70% the model begins to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Build a random forest with `n_estimators=100`. What is the accuracy, precision and recall and F1 score for the training and the test data? Plot the ROC curve? Is the model overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       160\n",
      "           1       0.60      0.58      0.59        71\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.71      0.70      0.71       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       340\n",
      "           1       1.00      0.99      1.00       197\n",
      "\n",
      "    accuracy                           1.00       537\n",
      "   macro avg       1.00      1.00      1.00       537\n",
      "weighted avg       1.00      1.00      1.00       537\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe98445e90>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe98445450>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8168133802816901"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "# CREATING RANDOM FORESTS\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 100)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred_test = rfc.predict(X_test)\n",
    "print(classification_report(y_test, rfc_pred_test))\n",
    "\n",
    "rfc_pred_train = rfc.predict(X_train)\n",
    "print(classification_report(y_train, rfc_pred_train))\n",
    "\n",
    "rfc_proba= rfc.predict_proba(X_test)\n",
    "rfc_proba_trian = rfc.predict_proba(X_train)\n",
    "\n",
    "#plot the ROC curve Test \n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, rfc_proba[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "\n",
    "fpr2, tpr2, _ = metrics.roc_curve(y_train, rfc_proba_trian[:,1])\n",
    "plt.plot(fpr2, tpr2, color = \"r\")\n",
    "\n",
    "metrics.auc(fpr, tpr)\n",
    "\n",
    "# Yes, our model is overfitting but it is not overfitting by too much. Our AUC is 80.02%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build another model to limit the overfitting problem by using `n_estimators=1000, max_depth=8` as your random forest parameters. Is the overfitting better now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       160\n",
      "           1       0.62      0.55      0.58        71\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.71      0.70      0.71       231\n",
      "weighted avg       0.75      0.76      0.75       231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       340\n",
      "           1       0.98      0.96      0.97       197\n",
      "\n",
      "    accuracy                           0.98       537\n",
      "   macro avg       0.98      0.98      0.98       537\n",
      "weighted avg       0.98      0.98      0.98       537\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbeb8eca890>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbeb8ecacd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9985368766796059"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe model is better with a max depth of 8 as the area under the curve very close to 1 meaning that it is a better \\noverall model than then one we had before with smaller forest and no depth.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc1 = RandomForestClassifier(n_estimators = 1000, max_depth = 8)\n",
    "rfc1.fit(X_train,y_train)\n",
    "\n",
    "rfc_pred_test1 = rfc1.predict(X_test)\n",
    "print(classification_report(y_test, rfc_pred_test1))\n",
    "\n",
    "rfc_pred_train2 = rfc1.predict(X_train)\n",
    "print(classification_report(y_train, rfc_pred_train2))\n",
    "\n",
    "rfc1_proba =rfc1.predict_proba(X_test)\n",
    "rfc1_proba_train =rfc1.predict_proba(X_train)\n",
    "\n",
    "# Plotting the ROC Curve\n",
    "fpr1, tpr1, _ = metrics.roc_curve(y_test, rfc1_proba[:,1])\n",
    "plt.plot(fpr1, tpr1)\n",
    "\n",
    "fpr1, tpr1, _ = metrics.roc_curve(y_train, rfc1_proba_train[:,1])\n",
    "plt.plot(fpr1, tpr1)\n",
    "\n",
    "#AUC                            \n",
    "metrics.auc(fpr1, tpr1)\n",
    "\n",
    "'''\n",
    "The model is better with a max depth of 8 as the area under the curve very close to 1 meaning that it is a better \n",
    "overall model than then one we had before with smaller forest and no depth.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the test precision curve  and accuracy curve for decision thresholds between 0.1 to 1 with a step of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjacobo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbedcd12450>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbedcd12b10>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresh = np.linspace(0, 0.9, 100)\n",
    "precision_list1 = []\n",
    "accuracy_list1 = []\n",
    "\n",
    "for th in thresh:\n",
    "    pred3 = rfc1_proba[:,1] >= th \n",
    "    precision_list1.append(metrics.precision_score(y_test, pred3))\n",
    "    accuracy_list1.append(metrics.accuracy_score(y_test, pred3))\n",
    "plt.plot(thresh, precision_list1)\n",
    "plt.plot(thresh, accuracy_list1, c = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally: \n",
    "- Write a few lines about each of the three models and if there is one superior model and why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.79\\nThe 3 models are effective, however, the forest model with a 1000 trees and a depth of 8 gives us the best model. \\nWe begin with an accuracy of 76% with the logistic regression model. \\nThe deep neural network model gives us an accuracy of 80% which is better than the logistic regression model.\\nFirst random forest give us an area under the curve of around 80%, however, the second forest we created had an \\narea under the curve of 99%. Since we have a higher area under the curve in the second forest that is a better \\nmore effective model. \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''0.79\n",
    "The 3 models are effective, however, the forest model with a 1000 trees and a depth of 8 gives us the best model. \n",
    "We begin with an accuracy of 76% with the logistic regression model. \n",
    "The deep neural network model gives us an accuracy of 80% which is better than the logistic regression model.\n",
    "First random forest give us an area under the curve of around 80%, however, the second forest we created had an \n",
    "area under the curve of 99%. Since we have a higher area under the curve in the second forest that is a better \n",
    "more effective model. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
